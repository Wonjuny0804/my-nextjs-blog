---
title: "Blog post Crawling Project 2"
date: "2022-04-29"
tags: ["Python", "Scrapy", "cron job"]
excerpt: "기술 블로그를 자주 읽는 입장에서 매번 들어가서 새로운 포스트가 올라왔는지 찾아보는 것도 귀찮고 나는 여러개의 블로그를 구도하기 때문에 하나로 모아보고 싶었다. AWS의 Lambda를 이용해서 scheduled job을, 그리고 python scrapy를 이용해서 웹에서 글들을 크롤링 해오자."
author: "Wonjun Jang"
---

크론잡과 웹크롤링, 이 두가지가 잘만 합쳐지면 해볼 수 있는 프로젝트가 된다.

### scrapy

이 프로젝트에서는 python 라이브러리인 Scrapy를 사용할 것이다. 이번에 쓴 글들은 [Scrapy 공식문서](https://docs.scrapy.org/en/latest/)를 참고했다.

먼저 python3 이 설치되어있다는 가정하에 나는 macOS를 사용하기 때문에

```bash
pip3 install Scrapy
```

를 해주면 되는데 이때 주의할 점은 **꼭 가상환경을 만들어서 하도록하자**

Scrapy 설치를 완료했다면 commandline 명령어를 이용해서 우리는 Scrapy 프로젝트를 setup할 수 있다.
